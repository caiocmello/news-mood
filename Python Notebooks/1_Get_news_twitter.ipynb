{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Oeg6JPbuar"
      },
      "outputs": [],
      "source": [
        "!pip install twarc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgjzxOVub0R-"
      },
      "outputs": [],
      "source": [
        "from twarc import Twarc2\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import date, datetime, timezone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jZfJPn4Bb4EG"
      },
      "outputs": [],
      "source": [
        "!twarc2 configure ##configure using your twitter keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_dHT1Stb9Az"
      },
      "outputs": [],
      "source": [
        "# Get timeline from tweet profile (BBCBreaking) from 2017-01-01 to 2017-12-30 file name bbc.jsonl\n",
        "!twarc2 timeline BBCBreaking --exclude-retweets --exclude-replies --start-time 2017-01-01 --end-time 2017-12-30 --use-search --tweet-fields text > bbc.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbVmbdW2cRL1"
      },
      "outputs": [],
      "source": [
        "bbc2017 = pd.read_json('bbc.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcNLaj52cZlW"
      },
      "outputs": [],
      "source": [
        "# Get only text from column 'data'\n",
        "texts = []\n",
        "for item in bbc17[\"data\"]:\n",
        "  for entry in item:\n",
        "    texts.append(entry[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NUr6Ya5cf8f"
      },
      "outputs": [],
      "source": [
        "# From list of text, get only URLs\n",
        "URL = []\n",
        "for text in texts:\n",
        "  clean_url = re.findall(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", text)\n",
        "  URL.append(clean_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9A1vE_Rcwly"
      },
      "outputs": [],
      "source": [
        "# Transform list of URLs into Pandas dataframe\n",
        "df = pd.DataFrame(URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njM6dK3tc6Nv"
      },
      "outputs": [],
      "source": [
        "# Save dataframe into CSV\n",
        "df.to_csv('bbc2017.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Get_news_twitter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}